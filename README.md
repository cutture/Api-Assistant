# ğŸš€ Enterprise API Integration Assistant

An AI-powered assistant that helps developers understand, document, and generate code for API integrations.

## âœ¨ Features

- **API Documentation Analysis**: Upload OpenAPI/Swagger specs and get instant insights
- **Code Generation**: Generate integration code in Python with best practices
- **RAG-Powered Q&A**: Ask questions about your APIs and get accurate answers
- **Documentation Gap Detection**: Identify missing or incomplete documentation
- **Local LLM Support**: Run entirely offline with Ollama

## ğŸ› ï¸ Tech Stack

- **UI**: Streamlit
- **LLM**: Ollama (DeepSeek Coder) / Groq (cloud fallback)
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Vector DB**: ChromaDB
- **Agent Framework**: LangGraph
- **API Parsing**: Prance + OpenAPI Spec Validator

## ğŸ“‹ Prerequisites

- Python 3.11+
- [Ollama](https://ollama.com/download) with `deepseek-coder:6.7b` model
- Git

## ğŸš€ Quick Start

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/api-assistant.git
cd api-assistant
```

### 2. Create virtual environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment

```bash
copy .env.example .env
# Edit .env with your settings (optional - defaults work for local development)
```

### 5. Start Ollama (if not running)

```bash
ollama serve
```

### 6. Run the application

```bash
streamlit run src/main.py
```

Open your browser to `http://localhost:8501`

## ğŸ“ Project Structure

```
api-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Streamlit entry point
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ core/                # Core business logic
â”‚   â”‚   â”œâ”€â”€ embeddings.py    # Embedding service
â”‚   â”‚   â”œâ”€â”€ vector_store.py  # ChromaDB operations
â”‚   â”‚   â””â”€â”€ llm_client.py    # LLM abstraction
â”‚   â”œâ”€â”€ parsers/             # API spec parsers
â”‚   â”‚   â””â”€â”€ openapi_parser.py
â”‚   â”œâ”€â”€ agents/              # LangGraph agents
â”‚   â”‚   â”œâ”€â”€ orchestrator.py  # Supervisor agent
â”‚   â”‚   â”œâ”€â”€ rag_agent.py     # Retrieval agent
â”‚   â”‚   â””â”€â”€ code_agent.py    # Code generation
â”‚   â””â”€â”€ ui/                  # Streamlit components
â”‚       â”œâ”€â”€ chat.py
â”‚       â””â”€â”€ sidebar.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/           # Vector database storage
â”‚   â””â”€â”€ uploads/             # User uploaded files
â”œâ”€â”€ tests/                   # Unit tests
â”œâ”€â”€ docker/                  # Docker configuration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ§ª Running Tests

```bash
pytest tests/ -v
```

## ğŸ³ Docker Deployment

```bash
cd docker
docker-compose up -d
```

## ğŸ“ Usage Examples

### Upload an API Spec

1. Click "Upload API Spec" in the sidebar
2. Select your OpenAPI/Swagger JSON or YAML file
3. Wait for processing to complete

### Ask Questions

- "How do I authenticate with this API?"
- "Generate Python code to call the /users endpoint"
- "What are all the available endpoints?"
- "Explain the response schema for GET /orders"

## ğŸ—ºï¸ Roadmap

- [x] Phase 1: RAG Foundation
- [ ] Phase 2: Agent Layer
- [ ] Phase 3: Production Hardening
- [ ] Phase 4: Advanced Features (multimodal, etc.)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) for the excellent AI framework
- [Ollama](https://ollama.com/) for local LLM inference
- [ChromaDB](https://www.trychroma.com/) for vector storage
- [Streamlit](https://streamlit.io/) for rapid UI development
